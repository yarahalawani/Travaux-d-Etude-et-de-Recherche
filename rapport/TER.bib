
@article{jang_q-learning_2019,
	title = {Q-{Learning} {Algorithms}: {A} {Comprehensive} {Classification} and {Applications}},
	volume = {7},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Q-{Learning} {Algorithms}},
	url = {https://ieeexplore.ieee.org/document/8836506/},
	doi = {10.1109/ACCESS.2019.2941229},
	abstract = {Q-learning is arguably one of the most applied representative reinforcement learning approaches and one of the off-policy strategies. Since the emergence of Q-learning, many studies have described its uses in reinforcement learning and artificial intelligence problems. However, there is an information gap as to how these powerful algorithms can be leveraged and incorporated into general artificial intelligence workflow. Early Q-learning algorithms were unsatisfactory in several aspects and covered a narrow range of applications. It has also been observed that sometimes, this rather powerful algorithm learns unrealistically and overestimates the action values hence abating the overall performance. Recently with the general advances of machine learning, more variants of Q-learning like Deep Q-learning which combines basic Q learning with deep neural networks have been discovered and applied extensively. In this paper, we thoroughly explain how Q-learning evolved by unraveling the mathematical complexities behind it as well its flow from reinforcement learning family of algorithms. Improved variants are fully described, and we categorize Q-learning algorithms into single-agent and multi-agent approaches. Finally, we thoroughly investigate up-to-date research trends and key applications that leverage Q-learning algorithms.},
	language = {en},
	urldate = {2024-05-10},
	journal = {IEEE Access},
	author = {Jang, Beakcheol and Kim, Myeonghwi and Harerimana, Gaspard and Kim, Jong Wook},
	year = {2019},
	pages = {133653--133667},
	file = {Jang et al. - 2019 - Q-Learning Algorithms A Comprehensive Classificat.pdf:/home/antoine/Zotero/storage/RATGME7J/Jang et al. - 2019 - Q-Learning Algorithms A Comprehensive Classificat.pdf:application/pdf},
}

@article{hutzler_automatic_2024,
	title = {Automatic discovery of cyberattacks, {IBISC}},
	url = {https://doi.org/10.5281/zenodo.11084685},
	abstract = {We present a method for the automatic discovery of cyberattacks within distributed information systems under abstract cost constraints. It is based on a formal model of cyberattack propagation generated from the specification of software and hardware architecture enriched with access control information. The ensuing network of automata, decorated with unitary attack costs, enables an analysis of cyberattack propagation under a cost criterion using an off-the-shelf model checker. The obtained propagation model is expressive enough to cover a wide range of attack/defence strategies, like false data injection or redundant data sources.},
	language = {en},
	author = {Hutzler, Guillaume and Klaudel, Hanna and Klaudel, Witold and Pommereau, Franck and Rataj, Artur},
	year = {2024},
	file = {Hutzler et al. - 2024 - Automatic discovery of cyberattacks.pdf:/home/antoine/Zotero/storage/58S8Q7R4/Hutzler et al. - 2024 - Automatic discovery of cyberattacks.pdf:application/pdf},
}

@inproceedings{xie_security_2013,
	address = {Beijing, China},
	title = {Security {Analysis} on {Cyber}-physical {System} {Using} {Attack} {Tree}},
	isbn = {978-0-7695-5120-3},
	url = {http://ieeexplore.ieee.org/document/6846669/},
	doi = {10.1109/IIH-MSP.2013.113},
	abstract = {Cyber-Physical System (CPS) is a system of system which integrates physical system with cyber capability in order to improve the physical performance. It is being widely used in areas closely related to national economy and people's livelihood, therefore CPS security problems have drawn a global attention and an appropriate risk assessment for CPS is in urgent need. Existing risk assessment for CPS always focuses on the reliability assessment, using Probability Risk Assessment (PRA). In this way, the assessment of physical part and cyber part is isolated as PRA is difficult to quantify the risks from the cyber world. Methodologies should be developed to assess the both parts as a whole system, considering this integrated system has a high coupling between the physical layer and cyber layer. In this paper, a risk assessment idea for CPS with the use of attack tree is proposed. Firstly, it presents a detailed description about the threat and vulnerability attributes of each leaf in an attack tree and tells how to assign value to its threat and vulnerability vector. Then this paper focuses on calculating the threat and vulnerability vector of an attack path with the use of the leaf vector values. Finally, damage is taken into account and an idea to calculate the risk value of the whole attack path is given.},
	language = {en},
	urldate = {2024-05-11},
	booktitle = {2013 {Ninth} {International} {Conference} on {Intelligent} {Information} {Hiding} and {Multimedia} {Signal} {Processing}},
	publisher = {IEEE},
	author = {Xie, Feng and Lu, Tianbo and Guo, Xiaobo and Liu, Jingli and Peng, Yong and Gao, Yang},
	month = oct,
	year = {2013},
	pages = {429--432},
	file = {Xie et al. - 2013 - Security Analysis on Cyber-physical System Using A.pdf:/home/antoine/Zotero/storage/9HFIUTES/Xie et al. - 2013 - Security Analysis on Cyber-physical System Using A.pdf:application/pdf},
}

@article{petit_potential_2014,
	title = {Potential {Cyberattacks} on {Automated} {Vehicles}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1524-9050, 1558-0016},
	url = {https://ieeexplore.ieee.org/document/6899663},
	doi = {10.1109/TITS.2014.2342271},
	abstract = {Vehicle automation has been one of the fundamental applications within the ﬁeld of intelligent transportation systems (ITS) since the start of ITS research in the mid-1980s. For most of this time, it has been generally viewed as a futuristic concept that is not close to being ready for deployment. However, recent development of “self-driving” cars and the announcement by car manufacturers of their deployment by 2020 show that this is becoming a reality. The ITS industry has already been focusing much of its attention on the concepts of “connected vehicles” (United States) or “cooperative ITS” (Europe). These concepts are based on communication of data among vehicles (V2V) and/or between vehicles and the infrastructure (V2I/I2V) to provide the information needed to implement ITS applications. The separate threads of automated vehicles and cooperative ITS have not yet been thoroughly woven together, but this will be a necessary step in the near future because the cooperative exchange of data will provide vital inputs to improve the performance and safety of the automation systems. Thus, it is important to start thinking about the cybersecurity implications of cooperative automated vehicle systems. In this paper, we investigate the potential cyberattacks speciﬁc to automated vehicles, with their special needs and vulnerabilities. We analyze the threats on autonomous automated vehicles and cooperative automated vehicles. This analysis shows the need for considerably more redundancy than many have been expecting. We also raise awareness to generate discussion about these threats at this early stage in the development of vehicle automation systems.},
	language = {en},
	urldate = {2024-05-11},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Petit, Jonathan and Shladover, Steven E.},
	year = {2014},
	pages = {1--11},
	file = {Petit et Shladover - 2014 - Potential Cyberattacks on Automated Vehicles.pdf:/home/antoine/Zotero/storage/3AUDLX84/Petit et Shladover - 2014 - Potential Cyberattacks on Automated Vehicles.pdf:application/pdf},
}

@article{ardito_artificial_2021,
	title = {An {Artificial} {Intelligence} {Cyberattack} {Detection} {System} to {Improve} {Threat} {Reaction} in e-{Health}},
	abstract = {In the e-Health domain, new and continuously evolving threats emerge every day. The security of e-Health telemonitoring systems is no longer negligible. In this paper, we propose a Cyberattack Detection System (CADS) model that exploits artificial intelligence techniques to detect anomalies without requiring a security analyst, explain the malicious activity, and display suspected attack data to healthcare personnel for feedback. The system description is contextualized to the case of the hacked remote patient health telemonitoring.},
	language = {en},
	author = {Ardito, Carmelo and Noia, Tommaso Di and Sciascio, Eugenio Di and Lofù, Domenico and Pazienza, Andrea and Vitulano, Felice},
	year = {2021},
	file = {Ardito et al. - An Artificial Intelligence Cyberattack Detection S.pdf:/home/antoine/Zotero/storage/A9MWAPMD/Ardito et al. - An Artificial Intelligence Cyberattack Detection S.pdf:application/pdf},
}

@inproceedings{mousavinejad_cyber_2018,
	address = {Cairns, Australia},
	title = {Cyber {Attack} {Detection} in {Platoon}-{Based} {Vehicular} {Networked} {Control} {Systems}},
	isbn = {978-1-5386-3705-0},
	url = {https://ieeexplore.ieee.org/document/8433814/},
	doi = {10.1109/ISIE.2018.8433814},
	abstract = {This paper is concerned with cyber attack detection problem in a platoon-based vehicular networked control system. In such a system, the information among vehicles is transmitted through a shared wireless communication network and also each vehicle has access to its own information measured by local sensors. These kind of systems are highly vulnerable to cyber attacks and therefore, cyber-security issues need to be properly addressed to ensure the safety of the systems. Among various cyber-security aspects, reliable attack detection is of utmost importance as the ability to detect cyber attacks in a timely manner can reduce the damage to the systems. Therefore, we present a cyber attack detection algorithm that is capable of detecting attacks violating both measurements and control command data. This algorithm is based on an ellipsoidal set-membership ﬁltering approach which consists of two sets: prediction ellipsoid set and an estimation ellipsoid set calculated through updating the prediction ellipsoid set with the measurement data. The detection method depends on the existence of intersection between these two sets computed by the ﬁlter. Simulation results for some possible cyber attacks are provided to demonstrate the effectiveness of the proposed method.},
	language = {en},
	urldate = {2024-05-11},
	booktitle = {2018 {IEEE} 27th {International} {Symposium} on {Industrial} {Electronics} ({ISIE})},
	publisher = {IEEE},
	author = {Mousavinejad, Eman and Yang, Fuwen and Han, Qing-Long and Qiu, Quanwei and Vlacic, Ljubo},
	month = jun,
	year = {2018},
	pages = {603--608},
	file = {Mousavinejad et al. - 2018 - Cyber Attack Detection in Platoon-Based Vehicular .pdf:/home/antoine/Zotero/storage/R87UXWWH/Mousavinejad et al. - 2018 - Cyber Attack Detection in Platoon-Based Vehicular .pdf:application/pdf},
}

@article{hasselt_double_nodate,
	title = {Double {Q}-learning},
	abstract = {In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is introduced because Q-learning uses the maximum action value as an approximation for the maximum expected action value. We introduce an alternative way to approximate the maximum expected value for any set of random variables. The obtained double estimator method is shown to sometimes underestimate rather than overestimate the maximum expected value. We apply the double estimator to Q-learning to construct Double Q-learning, a new off-policy reinforcement learning algorithm. We show the new algorithm converges to the optimal policy and that it performs well in some settings in which Q-learning performs poorly due to its overestimation.},
	language = {en},
	author = {Hasselt, Hado V},
	file = {Hasselt - Double Q-learning.pdf:/home/antoine/Zotero/storage/KQNE3CUA/Hasselt - Double Q-learning.pdf:application/pdf},
}

@incollection{gambardella_ant-q_1995,
	title = {Ant-{Q}: {A} {Reinforcement} {Learning} approach to the traveling salesman problem},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	isbn = {978-1-55860-377-6},
	shorttitle = {Ant-{Q}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9781558603776500396},
	abstract = {In this paper we introduce Ant-Q, a family of algorithms which present many similarities with Q-learning (Watkins, 1989), and which we apply to the solution of symmetric and asymmetric instances of the traveling salesman problem (TSP). Ant-Q algorithms were inspired by work on the ant system (AS), a distributed algorithm for combinatorial optimization based on the metaphor of ant colonies which was recently proposed in (Dorigo, 1992; Dorigo, Maniezzo and Colorni, 1996). We show that AS is a particular instance of the Ant-Q family, and that there are instances of this family which perform better than AS. We experimentally investigate the functioning of Ant-Q and we show that the results obtained by Ant-Q on symmetric TSP's are competitive with those obtained by other heuristic approaches based on neural networks or local search. Finally, we apply Ant-Q to some difficult asymmetric TSP's obtaining very good results: Ant-Q was able to find solutions of a quality which usually can be found only by very specialized algorithms.},
	language = {en},
	urldate = {2024-05-11},
	booktitle = {Machine {Learning} {Proceedings} 1995},
	publisher = {Elsevier},
	author = {Gambardella, Luca M. and Dorigo, Marco},
	year = {1995},
	doi = {10.1016/B978-1-55860-377-6.50039-6},
	pages = {252--260},
	file = {Gambardella et Dorigo - 1995 - Ant-Q A Reinforcement Learning approach to the tr.pdf:/home/antoine/Zotero/storage/IDK9B9HX/Gambardella et Dorigo - 1995 - Ant-Q A Reinforcement Learning approach to the tr.pdf:application/pdf},
}

@article{ono_multi-agent_1996,
	title = {Multi-agent {Reinforcement} {Learning}: {A} {Modular} {Approach}},
	abstract = {To investigate tile potentials and limitations of multi-agent reinforcement learning, several attempts have been madeto let multiple monolithic reinforcement-learning agents synthesize coordinated decision policies neededto accomplishtheir commognoals effectively. Mostof these straightforward reinforcement-learning approaches, howe{\textasciitilde}-er, scale poorly to morecomplexmulti-agent learning problems because the state space for each learning agent grows exponenti{\textasciitilde}dly in the numbeorf its partner agents engagedin the joint task. In this paper, weconsider a modifiedw{\textasciitilde}rsion of the Pursuit Problem as a multi-agent learning problem which is computationally intractable by those straightforward approaches. Weshowhowsuccessfully a collection of nmdular Q-learning hunter agents synthesize coordinated decision policies neededto capture a randomlyfleeing prey agent, by specializing their individual fimctionality and synthesizing herding behavior.},
	language = {en},
	author = {Ono, Norihiko and Fukumoto, Kenji},
	year = {1996},
	file = {Ono et Fukumoto - 1996 - Multi-agent Reinforcement Learning A Modular Appr.pdf:/home/antoine/Zotero/storage/S4YH8EIN/Ono et Fukumoto - 1996 - Multi-agent Reinforcement Learning A Modular Appr.pdf:application/pdf},
}

@misc{tang_va-learning_2023,
	title = {{VA}-learning as a more efficient alternative to {Q}-learning},
	url = {http://arxiv.org/abs/2305.18161},
	abstract = {In reinforcement learning, the advantage function is critical for policy improvement, but is often extracted from a learned Q-function. A natural question is: Why not learn the advantage function directly? In this work, we introduce VAlearning, which directly learns advantage function and value function using bootstrapping, without explicit reference to Q-functions. VA-learning learns off-policy and enjoys similar theoretical guarantees as Q-learning. Thanks to the direct learning of advantage function and value function, VA-learning improves the sample efficiency over Q-learning both in tabular implementations and deep RL agents on Atari-57 games. We also identify a close connection between VA-learning and the dueling architecture, which partially explains why a simple architectural change to DQN agents tends to improve performance.},
	language = {en},
	urldate = {2024-05-11},
	publisher = {arXiv},
	author = {Tang, Yunhao and Munos, Rémi and Rowland, Mark and Valko, Michal},
	month = may,
	year = {2023},
	note = {arXiv:2305.18161 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Tang et al. - 2023 - VA-learning as a more efficient alternative to Q-l.pdf:/home/antoine/Zotero/storage/RFTJLB82/Tang et al. - 2023 - VA-learning as a more efficient alternative to Q-l.pdf:application/pdf},
}

@article{konda_actor-critic_nodate,
	title = {Actor-{Critic} {Algorithms}},
	abstract = {We propose and analyze a class of actor-critic algorithms for simulation-based optimization of a Markov decision process over a parameterized family of randomized stationary policies. These are two-time-scale algorithms in which the critic uses TD learning with a linear approximation architecture and the actor is updated in an approximate gradient direction based on information provided by the critic. We show that the features for the critic should span a subspace prescribed by the choice of parameterization of the actor. We conclude by discussing convergence properties and some open problems.},
	language = {en},
	author = {Konda, Vijay R and Tsitsiklis, John N},
	file = {Konda et Tsitsiklis - Actor-Critic Algorithms.pdf:/home/antoine/Zotero/storage/BBVMLIFD/Konda et Tsitsiklis - Actor-Critic Algorithms.pdf:application/pdf},
}

@incollection{liu_deep_2017,
	address = {Cham},
	title = {Deep {Reinforcement} {Learning}: {From} {Q}-{Learning} to {Deep} {Q}-{Learning}},
	volume = {10637},
	isbn = {978-3-319-70092-2 978-3-319-70093-9},
	shorttitle = {Deep {Reinforcement} {Learning}},
	url = {https://link.springer.com/10.1007/978-3-319-70093-9_50},
	abstract = {As the two hottest branches of machine learning, deep learning and reinforcement learning both play a vital role in the ﬁeld of artiﬁcial intelligence. Combining deep learning with reinforcement learning, deep reinforcement learning is a method of artiﬁcial intelligence that is much closer to human learning. As one of the most basic algorithms for reinforcement learning, Q-learning is a discrete strategic learning algorithm that uses a reasonable strategy to generate an action. According to the rewards and the next state generated by the interaction of the action and the environment, optimal Q-function can be obtained. Furthermore, based on Q-learning and convolutional neural networks, the deep Q-learning with experience replay is developed in this paper. To ensure the convergence of value function, a discount factor is involved in the value function. The temporal diﬀerence method is introduced to training the Q-function or value function. At last, a detailed procedure is proposed to implement deep reinforcement learning.},
	language = {en},
	urldate = {2024-05-11},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer International Publishing},
	author = {Tan, Fuxiao and Yan, Pengfei and Guan, Xinping},
	editor = {Liu, Derong and Xie, Shengli and Li, Yuanqing and Zhao, Dongbin and El-Alfy, El-Sayed M.},
	year = {2017},
	doi = {10.1007/978-3-319-70093-9_50},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {475--483},
	file = {Tan et al. - 2017 - Deep Reinforcement Learning From Q-Learning to De.pdf:/home/antoine/Zotero/storage/C8KZSG24/Tan et al. - 2017 - Deep Reinforcement Learning From Q-Learning to De.pdf:application/pdf},
}

@misc{pommereau_fpomhyena_nodate,
	title = {fpom/hyena: {Hybrid} {Extensible} {Networks} of {Automata}},
	url = {https://github.com/fpom/hyena},
	urldate = {2024-05-11},
	author = {Pommereau, Franck},
	file = {fpom/hyena\: Hybrid Extensible Networks of Automata:/home/antoine/Zotero/storage/2EAPYMTV/hyena.html:text/html},
}

@inproceedings{junius_ho_hiq_2006,
	address = {Phoenix, AZ, USA},
	title = {{HiQ}: {A} {Hierarchical} {Q}-{Learning} {Algorithm} to {Solve} the {Reader} {Collision} {Problem}},
	isbn = {978-0-7695-2510-5},
	shorttitle = {{HiQ}},
	url = {http://ieeexplore.ieee.org/document/1581377/},
	doi = {10.1109/SAINT-W.2006.20},
	abstract = {HiQ is a hierarchical, online learning algorithm that ﬁnds dynamic solutions to the Reader Collision Problem in RFID systems. When the transmissions from one reader interfere with the operation of another reader, a reader collision occurs. The objective of the Reader Collision Problem is to minimize the reader collisions experienced by RFID readers while using the minimum number of frequencies and using the minimum total time for all readers to communicate successfully. HiQ attempts to minimize reader collisions by learning the collision patterns of the readers and by effectively assigning frequencies over time to ensure neighboring readers do not experience collisions from one another. HiQ is arranged hierarchically with distributed, local control. The algorithm is based on a type of reinforcement learning called Q-learning, which is used to determine frequency and time assignments. Through repeated interaction with the system, Q-learning attempts to discover an optimum frequency assignment over time. We show that HiQ ﬁnds optimal or near optimal solutions to the Reader Collision Problem.},
	language = {en},
	urldate = {2024-05-11},
	booktitle = {International {Symposium} on {Applications} and the {Internet} {Workshops} ({SAINTW}'06)},
	publisher = {IEEE},
	author = {{Junius Ho} and Engels, D.W. and Sarma, S.E.},
	year = {2006},
	pages = {88--91},
	file = {Junius Ho et al. - 2006 - HiQ A Hierarchical Q-Learning Algorithm to Solve .pdf:/home/antoine/Zotero/storage/MMTBFNYU/hiq-a-hierarchical-qlearning-algorithm-to-solve-the-reader-colli.pdf:application/pdf},
}

@inproceedings{melo_analysis_2008,
	address = {Helsinki, Finland},
	title = {An analysis of reinforcement learning with function approximation},
	isbn = {978-1-60558-205-4},
	url = {http://portal.acm.org/citation.cfm?doid=1390156.1390240},
	doi = {10.1145/1390156.1390240},
	abstract = {We address the problem of computing the optimal Q-function in Markov decision problems with inﬁnite state-space. We analyze the convergence properties of several variations of Q-learning when combined with function approximation, extending the analysis of TD-learning in (Tsitsiklis \& Van Roy, 1996a) to stochastic control settings. We identify conditions under which such approximate methods converge with probability 1. We conclude with a brief discussion on the general applicability of our results and compare them with several related works.},
	language = {en},
	urldate = {2024-05-11},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning - {ICML} '08},
	publisher = {ACM Press},
	author = {Melo, Francisco S. and Meyn, Sean P. and Ribeiro, M. Isabel},
	year = {2008},
	pages = {664--671},
	file = {Melo et al. - 2008 - An analysis of reinforcement learning with functio.pdf:/home/antoine/Zotero/storage/PJR7PF98/Melo et al. - 2008 - An analysis of reinforcement learning with functio.pdf:application/pdf},
}

@misc{noauthor_httpsuppaalorg_nodate,
	title = {https://uppaal.org/},
	url = {https://uppaal.org/},
	urldate = {2024-05-12},
	file = {Home | UPPAAL:/home/antoine/Zotero/storage/WIB8N8G4/uppaal.org.html:text/html},
}

@article{alur_theory_1994,
	title = {A theory of timed automata},
	volume = {126},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0304397594900108},
	doi = {10.1016/0304-3975(94)90010-8},
	abstract = {Alur, R. and D.L. Dill, A theory of timed automata, Theoretical Computer Science 126 (1994) 183-235. We propose timed (j\&e) automata to model the behavior of real-time systems over time. Our definition provides a simple, and yet powerful, way to annotate state-transition graphs with timing constraints using finitely many real-valued clocks. A timed automaton accepts timed words-infinite sequences in which a real-valued time of occurrence is associated with each symbol. We study timed automata from the perspective of formal language theory: we consider closure properties, decision problems, and subclasses. We consider both nondeterministic and deterministic transition structures, and both Biichi and Muller acceptance conditions. We show that nondeterministic timed automata are closed under union and intersection, but not under complementation, whereas deterministic timed Muller automata are closed under all Boolean operations. The main construction of the paper is an (PSPACE) algorithm for checking the emptiness of the language of a (nondeterministic) timed automaton. We also prove that the universality problem and the language inclusion problem are solvable only for the deterministic automata: both problems are undecidable (II i-hard) in the nondeterministic case and PSPACE-complete in the deterministic case. Finally, we discuss the application of this theory to automatic verification of real-time requirements of finite-state systems.},
	language = {en},
	number = {2},
	urldate = {2024-05-12},
	journal = {Theoretical Computer Science},
	author = {Alur, Rajeev and Dill, David L.},
	month = apr,
	year = {1994},
	pages = {183--235},
	file = {Alur et Dill - 1994 - A theory of timed automata.pdf:/home/antoine/Zotero/storage/9U8JBHEZ/Alur et Dill - 1994 - A theory of timed automata.pdf:application/pdf},
}

@misc{noauthor_httpswwwgeeksforgeeksorgq-learning--python_2019,
	title = {https://www.geeksforgeeks.org/q-learning-in-python/},
	url = {https://www.geeksforgeeks.org/q-learning-in-python/},
	abstract = {A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.},
	language = {en-US},
	urldate = {2024-05-12},
	journal = {GeeksforGeeks},
	month = feb,
	year = {2019},
	note = {Section: AI-ML-DS},
	file = {Snapshot:/home/antoine/Zotero/storage/2VZRL9CT/q-learning-in-python.html:text/html},
}

@misc{xu_autoattacker_2024,
	title = {{AutoAttacker}: {A} {Large} {Language} {Model} {Guided} {System} to {Implement} {Automatic} {Cyber}-attacks},
	shorttitle = {{AutoAttacker}},
	url = {http://arxiv.org/abs/2403.01038},
	abstract = {Large language models (LLMs) have demonstrated impressive results on natural language tasks, and security researchers are beginning to employ them in both offensive and defensive systems. In cyber-security, there have been multiple research efforts that utilize LLMs focusing on the pre-breach stage of attacks like phishing and malware generation. However, so far there lacks a comprehensive study regarding whether LLM-based systems can be leveraged to simulate the postbreach stage of attacks that are typically human-operated, or “hands-on-keyboard” attacks, under various attack techniques and environments.},
	language = {en},
	urldate = {2024-05-12},
	publisher = {arXiv},
	author = {Xu, Jiacen and Stokes, Jack W. and McDonald, Geoff and Bai, Xuesong and Marshall, David and Wang, Siyue and Swaminathan, Adith and Li, Zhou},
	month = mar,
	year = {2024},
	note = {arXiv:2403.01038 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Xu et al. - 2024 - AutoAttacker A Large Language Model Guided System.pdf:/home/antoine/Zotero/storage/R37Z4SNC/Xu et al. - 2024 - AutoAttacker A Large Language Model Guided System.pdf:application/pdf},
}

@article{law_security_2015,
	title = {Security {Games} for {Risk} {Minimization} in {Automatic} {Generation} {Control}},
	volume = {30},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0885-8950, 1558-0679},
	url = {http://ieeexplore.ieee.org/document/6824274/},
	doi = {10.1109/TPWRS.2014.2326403},
	abstract = {The power grid is a critical infrastructure that must be protected against potential threats. While modern technologies at the center of the ongoing smart grid evolution increase its operational efﬁciency, they also make it more susceptible to malicious attacks such as false data injection to electronic monitoring systems. This paper presents a game-theoretic approach to smart grid security by combining quantitative risk management techniques with decision making on protective measures. The consequences of data injection attacks are quantiﬁed using a risk assessment process where the well-known conditional value-at-risk (CVaR) measure provides an estimate of the defender’s loss due to load shed in simulated scenarios. The calculated risks are then incorporated into a stochastic security game model as input parameters. The decisions on defensive measures are obtained by solving the game using dynamic programming techniques which take into account resource constraints. Thus, the formulated security game provides an analytical framework for choosing the best response strategies against attackers and minimizing potential risks. The theoretical results obtained are demonstrated through numerical examples. Simulation results show that different risk measures lead to different defense strategies, but the CVaR measure prioritizes high-loss tail events.},
	language = {en},
	number = {1},
	urldate = {2024-05-12},
	journal = {IEEE Transactions on Power Systems},
	author = {Law, Yee Wei and Alpcan, Tansu and Palaniswami, Marimuthu},
	month = jan,
	year = {2015},
	pages = {223--232},
	file = {Law et al. - 2015 - Security Games for Risk Minimization in Automatic .pdf:/home/antoine/Zotero/storage/LISB7TDR/Law et al. - 2015 - Security Games for Risk Minimization in Automatic .pdf:application/pdf},
}

@inproceedings{kern_model-based_2021,
	title = {Model-based {Attack} {Tree} {Generation} for {Cybersecurity} {Risk}-{Assessments} in {Automotive}},
	url = {https://ieeexplore.ieee.org/abstract/document/9582462},
	doi = {10.1109/ISSE51541.2021.9582462},
	abstract = {Networked and highly automated driver assistance systems require interfaces to the outside world and within the vehicle. These can potentially be used for cybersecurity attacks. Therefore, cybersecurity risk analyses are essential to adequately counter cybersecurity threats. Through UNECE Regulations No. 155, cybersecurity risk assessments, are mandatory for all new cars from 2024. The ISO/SAE 21434 standard “Road vehicles Cybersecurity engineering”, defines requirements for cybersecurity risk management with regard to electrical/electronic systems and components. In this context, it is imperative that possible attack paths are investigated. The creation of these attack paths is labor-intensive and should relate to the preliminary system architecture. Automatic attack tree generation could help to reduce the effort to create attack paths manually. This paper presents a new approach to generate relevant attack paths in a semi-automated way, taking the attack motivation and functional dependencies into account. This can shift the effort of creating attack trees in the concept phase to the preliminary system description and allows cybersecurity experts to focus more on aspects that require their creativity and expertise.},
	urldate = {2024-05-12},
	booktitle = {2021 {IEEE} {International} {Symposium} on {Systems} {Engineering} ({ISSE})},
	author = {Kern, Matthias and Liu, Bo and Betancourt, Victor Pazmino and Becker, Jürgen},
	month = sep,
	year = {2021},
	note = {ISSN: 2687-8828},
	keywords = {Attack Tree, Automobiles, Computer security, Cyber-Physical System, Cyber-Security-Risk-Analysis, Electrical/Electronic-Architecture, Modeling, Regulation, Risk management, Standards, Systems architecture},
	pages = {1--7},
	file = {IEEE Xplore Abstract Record:/home/antoine/Zotero/storage/T223FMKF/9582462.html:text/html},
}

@incollection{sowka_review_2023,
	address = {Singapore},
	title = {A {Review} on {Automatic} {Generation} of {Attack} {Trees} and {Its} {Application} to {Automotive} {Cybersecurity}},
	isbn = {978-981-9921-15-7},
	url = {https://doi.org/10.1007/978-981-99-2115-7_7},
	abstract = {A comprehensive cybersecurity evaluation of automotive on-board networks has become a crucial antecedent to the commercial distribution of vehicles. However, the means to perform the required testing and risk assessment are limited due to the complex and increasingly obscure nature of automotive systems. To rectify this, several approaches have been put forward to systematise and automate the process of evaluating cybersecurity in vehicular systems, but these still require a significant amount of expert input. Accordingly, this work evaluates the existing state of the art in attack tree generation as a means towards automation and systematisation of automotive cybersecurity assurance in addition to considering the potential of novel machine learning methods in pursuing further automation.},
	language = {en},
	urldate = {2024-05-12},
	booktitle = {Artificial {Intelligence} and {Cyber} {Security} in {Industry} 4.0},
	publisher = {Springer Nature},
	author = {Sowka, Kacper and Palade, Vasile and Jadidbonab, Hesamaldin and Wooderson, Paul and Nguyen, Hoang},
	editor = {Sarveshwaran, Velliangiri and Chen, Joy Iong-Zong and Pelusi, Danilo},
	year = {2023},
	doi = {10.1007/978-981-99-2115-7_7},
	pages = {165--193},
}

@article{hu_nash_nodate,
	title = {Nash {Q}-{Learning} for {General}-{Sum} {Stochastic} {Games}},
	abstract = {We extend Q-learning to a noncooperative multiagent context, using the framework of generalsum stochastic games. A learning agent maintains Q-functions over joint actions, and performs updates based on assuming Nash equilibrium behavior over the current Q-values. This learning protocol provably converges given certain restrictions on the stage games (deﬁned by Q-values) that arise during learning. Experiments with a pair of two-player grid games suggest that such restrictions on the game structure are not necessarily required. Stage games encountered during learning in both grid environments violate the conditions. However, learning consistently converges in the ﬁrst grid game, which has a unique equilibrium Q-function, but sometimes fails to converge in the second, which has three different equilibrium Q-functions. In a comparison of ofﬂine learning performance in both games, we ﬁnd agents are more likely to reach a joint optimal path with Nash Q-learning than with a single-agent Q-learning method. When at least one agent adopts Nash Q-learning, the performance of both agents is better than using single-agent Q-learning. We have also implemented an online version of Nash Q-learning that balances exploration with exploitation, yielding improved performance.},
	language = {en},
	author = {Hu, Junling and Wellman, Michael P},
	file = {Hu et Wellman - Nash Q-Learning for General-Sum Stochastic Games.pdf:/home/antoine/Zotero/storage/4U4SEZ76/Hu et Wellman - Nash Q-Learning for General-Sum Stochastic Games.pdf:application/pdf},
}

@inproceedings{panfili_game-theoretical_2018,
	title = {A {Game}-{Theoretical} {Approach} to {Cyber}-{Security} of {Critical} {Infrastructures} {Based} on {Multi}-{Agent} {Reinforcement} {Learning}},
	url = {https://ieeexplore.ieee.org/abstract/document/8442695},
	doi = {10.1109/MED.2018.8442695},
	abstract = {This paper presents a control strategy for Cyber-Physical System defense developed in the framework of the European Project ATENA, that concerns Critical Infrastructure (CI) protection. The aim of the controller is to find the optimal security configuration, in terms of countermeasures to implement, in order to address the system vulnerabilities. The attack/defense problem is modeled as a multi-agent general sum game, where the aim of the defender is to prevent the most damage possible by finding an optimal trade-off between prevention actions and their costs. The problem is solved utilizing Reinforcement Learning and simulation results provide a proof of the proposed concept, showing how the defender of the protected CI is able to minimize the damage caused by his her opponents by finding the Nash equilibrium of the game in the zero-sum variant, and, in a more general scenario, by driving the attacker in the position where the damage she/he can cause to the infrastructure is lower than the cost it has to sustain to enforce her/his attack strategy.},
	urldate = {2024-05-12},
	booktitle = {2018 26th {Mediterranean} {Conference} on {Control} and {Automation} ({MED})},
	author = {Panfili, Martina and Giuseppi, Alessandro and Fiaschetti, Andrea and Al-Jibreen, Homoud B. and Pietrabissa, Antonio and Delli Priscoli, Franchisco},
	month = jun,
	year = {2018},
	note = {ISSN: 2473-3504},
	keywords = {Aerospace electronics, Composable Security, Critical infrastructure, Critical Infrastructure Protection, Games, Learning (artificial intelligence), Nash equilibrium, Reinforcement Learning, Security, Stochastic Games, Vulnerability Management},
	pages = {460--465},
	file = {IEEE Xplore Abstract Record:/home/antoine/Zotero/storage/V3XHJ3RL/8442695.html:text/html;Version soumise:/home/antoine/Zotero/storage/3QMG7NYB/Panfili et al. - 2018 - A Game-Theoretical Approach to Cyber-Security of C.pdf:application/pdf},
}
